import librosa
import soundfile as sf
from typing import List, Dict
import os
import glob
import subprocess
from dotenv import load_dotenv
import torch
from faster_whisper import WhisperModel
from huggingface_hub import login


def find_cudnn_version():
    """ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ CUDNN ë²„ì „ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # NVIDIA driver ì •ë³´ ì¶œë ¥
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, text=True)
        print(f"NVIDIA Driver ì •ë³´:\n{result.stdout}")

        # CUDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²€ìƒ‰
        cudnn_paths = []
        for path in ['/usr/lib/x86_64-linux-gnu/', '/usr/local/cuda/lib64/',
                     '/usr/local/cuda/targets/x86_64-linux/lib/']:
            if os.path.exists(path):
                cudnn_files = glob.glob(f"{path}libcudnn*.so*")
                if cudnn_files:
                    cudnn_paths.extend(cudnn_files)

        if cudnn_paths:
            print(f"ë°œê²¬ëœ CUDNN ë¼ì´ë¸ŒëŸ¬ë¦¬:\n{cudnn_paths}")
            return "found"
        else:
            print("CUDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "not_found"
    except Exception as e:
        print(f"CUDNN ë²„ì „ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return "error"


class LocalFasterWhisperTranscriber:
    def __init__(self, model_size="large-v3", hf_token=None, force_cpu=False):
        """
        ë¡œì»¬ Faster Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ìŒì„± ì¸ì‹ê¸° ì´ˆê¸°í™”

        Args:
            model_size: ì‚¬ìš©í•  Whisper ëª¨ë¸ í¬ê¸° ("tiny", "base", "small", "medium", "large-v2", "large-v3")
            hf_token: Hugging Face í† í° (ë¹„ê³µê°œ ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìš”)
            force_cpu: CPU ëª¨ë“œ ê°•ì œ ì‚¬ìš© ì—¬ë¶€
        """
        load_dotenv()
        self.sr = 16000
        self.language = "ko"

        # HuggingFace í† í°ì´ ì œê³µë˜ë©´ ë¡œê·¸ì¸
        if hf_token:
            login(token=hf_token)
            print("Logged in to Hugging Face")

        # GPU ì •ë³´ ì¶œë ¥ ë° CUDNN ë²„ì „ í™•ì¸
        has_cuda = torch.cuda.is_available()
        if has_cuda:
            print(f"CUDA ì‚¬ìš© ê°€ëŠ¥. ë””ë°”ì´ìŠ¤ ìˆ˜: {torch.cuda.device_count()}")
            print(f"CUDA ë²„ì „: {torch.version.cuda}")
            for i in range(torch.cuda.device_count()):
                print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

            # CUDNN ë²„ì „ í™•ì¸
            cudnn_status = find_cudnn_version()
        else:
            cudnn_status = "no_cuda"

        # ë””ë°”ì´ìŠ¤ ì„ íƒ
        if force_cpu or cudnn_status != "found":
            self.device = "cpu"
            self.compute_type = "int8"
            print("CPU ëª¨ë“œ ì‚¬ìš© - CUDNN ë¬¸ì œ ë˜ëŠ” ê°•ì œ CPU ëª¨ë“œ ì„¤ì •")
        else:
            try:
                # PyTorch CUDA ê¸°ëŠ¥ í™•ì¸
                x = torch.zeros(1, device="cuda")
                del x
                print("CUDA ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ")

                self.device = "cuda"

                # CUDA ì•„í‚¤í…ì²˜ì— ë”°ë¥¸ compute_type ì„¤ì •
                gpu_name = torch.cuda.get_device_name(0).lower()
                if any(arch in gpu_name for arch in ['a100', 'a10', 'h100']):
                    self.compute_type = "float16"  # Ampere/Hopper ì•„í‚¤í…ì²˜
                    print("ìµœì‹  GPU ì•„í‚¤í…ì²˜ ê°ì§€: float16 ì‚¬ìš©")
                else:
                    self.compute_type = "int8"  # êµ¬í˜• GPU
                    print("ì´ì „ GPU ì•„í‚¤í…ì²˜ ê°ì§€: int8 ì‚¬ìš©")
            except Exception as e:
                print(f"CUDA í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
                self.device = "cpu"
                self.compute_type = "int8"

        print(f"ìµœì¢… ì„¤ì • - Device: {self.device}, Compute type: {self.compute_type}")

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (CUDNN ë¬¸ì œ í•´ê²° ì‹œë„)
        if self.device == "cuda":
            try:
                os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # ì²« ë²ˆì§¸ GPU ì„ íƒ
                # CTranslate2 ë¡œê¹… í™œì„±í™”
                os.environ["CT2_VERBOSE"] = "1"
            except Exception as e:
                print(f"í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì‹¤íŒ¨: {str(e)}")

        # ë¡œì»¬ Faster Whisper ëª¨ë¸ ë¡œë“œ
        print(f"Loading Faster Whisper {model_size} model...")
        try:
            # GPU ë˜ëŠ” CPU ëª¨ë“œì— ë”°ë¥¸ ì´ˆê¸°í™”
            if self.device == "cuda":
                try:
                    self.model = WhisperModel(
                        model_size,
                        device=self.device,
                        compute_type=self.compute_type,
                        download_root="./models",
                        local_files_only=False,
                        # local_files_only=True,
                    )
                    print("Faster Whisper model loaded successfully (GPU mode)")
                except Exception as e:
                    print(f"GPU ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                    print("compute_type ë³€ê²½ ì‹œë„...")

                    # compute_type ë³€ê²½ ì‹œë„
                    for compute_type in ["int8", "int8_float16", "float32"]:
                        try:
                            print(f"{compute_type} ì‹œë„ ì¤‘...")
                            self.model = WhisperModel(
                                model_size,
                                device=self.device,
                                compute_type=compute_type,
                                download_root="./models"
                            )
                            self.compute_type = compute_type
                            print(f"Faster Whisper model loaded successfully with {compute_type}")
                            break
                        except Exception as e2:
                            print(f"{compute_type} ì‹¤íŒ¨: {str(e2)}")
                    else:
                        # ëª¨ë“  compute_typeì´ ì‹¤íŒ¨í•˜ë©´ CPUë¡œ í´ë°±
                        print("ëª¨ë“  GPU ì˜µì…˜ ì‹¤íŒ¨, CPU ëª¨ë“œë¡œ ì „í™˜")
                        self.device = "cpu"
                        self.compute_type = "int8"
                        self.model = WhisperModel(
                            model_size,
                            device="cpu",
                            compute_type="int8",
                            download_root="./models",
                            cpu_threads=4
                        )
                        print("Faster Whisper model loaded successfully (CPU fallback)")
            else:
                # CPU ëª¨ë“œ ì´ˆê¸°í™”
                self.model = WhisperModel(
                    model_size,
                    device="cpu",
                    compute_type="int8",
                    download_root="./models",
                    cpu_threads=4
                )
                print("Faster Whisper model loaded successfully (CPU mode)")
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë”© ìµœì¢… ì‹¤íŒ¨: {str(e)}")
            raise RuntimeError(f"Faster Whisper ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

    def segment_audio(self, audio_file: str, start: float, end: float, output_file: str) -> str:
        """ì£¼ì–´ì§„ êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ë¥¼ ì˜ë¼ì„œ ì €ì¥í•©ë‹ˆë‹¤."""
        y, sr = librosa.load(audio_file, sr=self.sr)
        start_sample = int(start * sr)
        end_sample = int(end * sr)
        sf.write(output_file, y[start_sample:end_sample], sr)
        return output_file, y[start_sample:end_sample], start_sample, end_sample

    def transcribe_segment(self, segment_file: str, prompt: str = "", log_prob_threshold: float = -1.0) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ë³„ ìŒì„± ì¸ì‹ ìˆ˜í–‰ (ì´ì „ í”„ë¡¬í”„íŠ¸ í™œìš©)."""
        try:
            # Faster Whisper ëª¨ë¸ë¡œ ì¸ì‹ ìˆ˜í–‰
            segments, _ = self.model.transcribe(
                segment_file,
                language=self.language,
                initial_prompt=prompt,
                beam_size=5,
                length_penalty=0.99,
                repetition_penalty=1.5,
                temperature=0.,
                condition_on_previous_text=False,
                vad_filter=True,
                vad_parameters={"threshold": 0.5}
            )

            # ğŸ¯ log_prob_threshold ì ìš©: ì‹ ë¢°ë„ ë‚®ì€ ë¬¸ì¥ ì œê±°
            filtered_segments = [seg for seg in segments if seg.avg_logprob > log_prob_threshold]

            # ê²°ê³¼ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            full_text = " ".join([segment.text for segment in filtered_segments])

            # ê²°ê³¼ ë°˜í™˜
            return full_text.strip()

        except Exception as e:
            print(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
            return ""

    def transcribe_segments(self, audio_file: str, segments: List[Dict]) -> Dict[str, List[Dict]]:
        """ì„¸ê·¸ë¨¼íŠ¸ë³„ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ë°©ì‹ìœ¼ë¡œ ìŒì„± ì¸ì‹ ìˆ˜í–‰."""
        # speaker_transcripts = {"SPK0": [], "SPK1": []}
        speaker_transcripts = {}
        prompt = ""  # í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”

        total_segments = len(segments)
        for idx, segment in enumerate(segments):
            print(f"ì²˜ë¦¬ ì¤‘: ì„¸ê·¸ë¨¼íŠ¸ {idx + 1}/{total_segments}")
            # ì„¸ê·¸ë¨¼íŠ¸ ìë¥´ê¸°
            segment_file = f"segment_{idx}.wav"
            _, y, start_sample, end_sample = self.segment_audio(audio_file, segment['start'], segment['end'],
                                                                segment_file)

            # ì´ì „ í”„ë¡¬í”„íŠ¸ ë°˜ì˜í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì‹
            text = self.transcribe_segment(segment_file, prompt=prompt)

            # segment_fileì„ ì½ì–´ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ë³€í™˜
            with open(segment_file, "rb") as file:
                audio_binary = file.read()

            os.remove(segment_file)

            # í”„ë¡¬í”„íŠ¸ ëˆ„ì 
            prompt += " " + text  # ì´ì „ ê²°ê³¼ ì¶”ê°€
            if len(prompt) > 200:  # 200ìë¥¼ ì´ˆê³¼í•˜ë©´
                prompt = prompt[-200:]  # ë’¤ì—ì„œ 200ìë§Œ ìœ ì§€

            speaker = segment['speaker']
            if speaker not in speaker_transcripts:
                speaker_transcripts[speaker] = []

            # ê²°ê³¼ ì €ì¥
            speaker_transcripts[segment['speaker']].append({
                "start": segment['start'],
                "end": segment['end'],
                "text": text,
                "audio": audio_binary  # í•´ë‹¹ êµ¬ê°„ì˜ ì˜¤ë””ì˜¤ ë°ì´í„° ì €ì¥
            })
            print(f"ì„¸ê·¸ë¨¼íŠ¸ {idx + 1} ê²°ê³¼: {text[:50]}..." if len(text) > 50 else f"ì„¸ê·¸ë¨¼íŠ¸ {idx + 1} ê²°ê³¼: {text}")

        return speaker_transcripts

    def format_conversation(self, speaker_transcripts: Dict[str, List[Dict]]) -> str:
        """ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë°œí™” ë‚´ìš©ì„ í¬ë§·íŒ…."""
        # ëª¨ë“  ë°œí™”ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ì— ëª¨ì€ ë’¤, ì‹œì‘ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_segments = []
        for speaker, segments in speaker_transcripts.items():
            for seg in segments:
                all_segments.append({
                    "speaker": speaker,
                    "start": seg['start'],
                    "end": seg['end'],
                    "text": seg['text']
                })

        # ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬
        all_segments.sort(key=lambda x: x['start'])

        # í¬ë§·íŒ…
        formatted_text = ""
        for seg in all_segments:
            formatted_text += f"[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['speaker']}: {seg['text']}\n"
        return formatted_text


if __name__ == "__main__":
    from diarize_speaker import SpeakerDiarizer

    # Hugging Face í† í° ì„¤ì • (í•„ìš”ì‹œ)
    hf_token = os.getenv("HF_TOKEN")

    # ì˜¤ë””ì˜¤ íŒŒì¼ ë° í™”ì êµ¬ë¶„ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    audio_file = "audio.wav"
    diarizer = SpeakerDiarizer()
    diarization_results = diarizer.process_audio(audio_file)
    segments = diarizer.get_results_as_list(diarization_results)

    # GPU ì‚¬ìš© ì‹œë„ (force_cpu=False)
    transcriber = LocalFasterWhisperTranscriber(model_size="large-v3", hf_token=hf_token, force_cpu=False)
    transcripts = transcriber.transcribe_segments(audio_file, segments)

    # ê²°ê³¼ ì¶œë ¥
    print("\n=== íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ===\n")
    print(transcriber.format_conversation(transcripts))